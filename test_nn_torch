import torch
import torch.nn as nn
import torch.optim as optim

#device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
device = "cpu"

# Входные данные
xs = torch.tensor([[3, 5], [5, 1], [10, 2]], dtype=torch.float32, device = device)
ys = torch.tensor([[75], [82], [93]], dtype=torch.float32, device = device)

# Нормализация данных
xs = xs / torch.max(xs, dim=0)[0]
ys = ys / 100  # Максимальное значение тестового балла - 100

# Определение модели нейронной сети
class NeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(NeuralNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Создание экземпляра модели
input_size = 2
hidden_size = 3
output_size = 1
model = NeuralNetwork(input_size, hidden_size, output_size)

model.to(device)
# Проверка текущего устройства выполнения модели
# for param in model.parameters():
#     print("Текущее выполнение параметра:", param.device)

# Определение функции потерь и оптимизатора
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.03)

# Обучение модели
max_iterations = 1000000
delta = 0.0000001
prev_loss = float("inf")
iteration = 0

while iteration < max_iterations:
    # Прямой проход
    outputs = model(xs)
    loss = criterion(outputs, ys)

    # Обратное распространение
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # Проверка условия остановки
    if abs(loss.item() - prev_loss) <= delta:
        break

    prev_loss = loss.item()
    iteration += 1

# Проверка предсказаний
y_pred = model(xs)
print(y_pred * 100)  # Умножение на 100 для получения оригинальной шкалы баллов
